{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dancing princesses Text Analysis\n",
    "From this link https://notebooks.azure.com/priesterkc/projects/DABmaterial/tree/Lv2%20Data%20Analytics/datasets, download the 12dancingprincesses.txt file. Then read the file and use the NLTK library to tokenize each word in the text.\n",
    "\n",
    "After tokenizing each word, then remove the punctuation and filler words (stopwords) from the list of tokens. Lastly, get the top 10 words from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dancing.txt', 'r') as f:   # Read text file \n",
    "    princess = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8363"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(princess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "princess = princess.lower() # Change the text into lower cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chart in '\\n’‘':  # get rid of apostrophe sign \n",
    "    princess = princess.replace(chart , '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in princess:\n",
    "    cline = line.strip() #get rid of newline character\n",
    "\n",
    "    if cline == '': pass  #this will skip over lines that only had a newline and are now blank\n",
    "    else:\n",
    "        tknls_princess = word_tokenize(princess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1684"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tknls_princess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'twelve',\n",
       " 'dancing',\n",
       " 'princessesthere',\n",
       " 'was',\n",
       " 'a',\n",
       " 'king',\n",
       " 'who',\n",
       " 'had',\n",
       " 'twelve']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknls_princess[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_stopwords = stopwords.words('english')\n",
    "eng_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = []\n",
    "    #remove filler words\n",
    "for token in tknls_princess:\n",
    "    if token not in eng_stopwords:\n",
    "        clean_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "852"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twelve',\n",
       " 'dancing',\n",
       " 'princessesthere',\n",
       " 'king',\n",
       " 'twelve',\n",
       " 'beautiful',\n",
       " 'daughters',\n",
       " '.',\n",
       " 'slept',\n",
       " 'intwelve',\n",
       " 'beds',\n",
       " 'one',\n",
       " 'room',\n",
       " ';',\n",
       " 'went']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the puntuation tokens from the list\n",
    "for word in clean_tokens:\n",
    "    if word in punctuation:\n",
    "        clean_tokens.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twelve',\n",
       " 'dancing',\n",
       " 'princessesthere',\n",
       " 'king',\n",
       " 'twelve',\n",
       " 'beautiful',\n",
       " 'daughters',\n",
       " 'slept',\n",
       " 'intwelve',\n",
       " 'beds',\n",
       " 'one',\n",
       " 'room',\n",
       " 'went',\n",
       " 'bed',\n",
       " 'doors']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tokens[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 2,\n",
       "          '--': 2,\n",
       "          ';': 1,\n",
       "          'able': 1,\n",
       "          'adventure': 1,\n",
       "          'afraid': 1,\n",
       "          'afterwards': 1,\n",
       "          'allaway': 1,\n",
       "          'allis': 1,\n",
       "          'already': 1,\n",
       "          'always': 1,\n",
       "          'alwayssilenced': 1,\n",
       "          'anddressed': 1,\n",
       "          'andthe': 2,\n",
       "          'andthen': 1,\n",
       "          'andwhen': 2,\n",
       "          'another': 2,\n",
       "          'answered': 1,\n",
       "          'approach.then': 1,\n",
       "          'asked': 3,\n",
       "          'asleep': 2,\n",
       "          'asleep.then': 1,\n",
       "          'atnight': 1,\n",
       "          'atoken': 1,\n",
       "          'away': 3,\n",
       "          'awoke': 1,\n",
       "          'back': 1,\n",
       "          'battleand': 1,\n",
       "          'beautiful': 1,\n",
       "          'beautifully.the': 1,\n",
       "          'become': 1,\n",
       "          'becut': 1,\n",
       "          'bed': 6,\n",
       "          'beds': 2,\n",
       "          'been.as': 1,\n",
       "          'been.then': 1,\n",
       "          'beendancing': 1,\n",
       "          'began': 1,\n",
       "          'begin': 1,\n",
       "          'behind': 1,\n",
       "          'best': 1,\n",
       "          'better': 1,\n",
       "          'boat': 4,\n",
       "          'boats': 1,\n",
       "          'boatseems': 1,\n",
       "          'boxes': 1,\n",
       "          'branch': 2,\n",
       "          'branches': 1,\n",
       "          'bring': 1,\n",
       "          'broke': 1,\n",
       "          'brokeoff': 1,\n",
       "          'brought': 2,\n",
       "          'butthe': 1,\n",
       "          'came': 10,\n",
       "          'care': 2,\n",
       "          'carried': 1,\n",
       "          'castle': 3,\n",
       "          'chamber': 3,\n",
       "          'chanced': 1,\n",
       "          'choose': 1,\n",
       "          'chosen': 1,\n",
       "          'clapped': 1,\n",
       "          'cloak': 2,\n",
       "          'clothes': 1,\n",
       "          'come': 1,\n",
       "          'confessed': 1,\n",
       "          'could': 1,\n",
       "          'coulddiscover': 1,\n",
       "          'country': 1,\n",
       "          'creature': 1,\n",
       "          'cried': 1,\n",
       "          'crying': 1,\n",
       "          'cup': 5,\n",
       "          'cups': 1,\n",
       "          'dame': 1,\n",
       "          'dance': 3,\n",
       "          'danced': 5,\n",
       "          'dancing': 2,\n",
       "          'daughter': 1,\n",
       "          'daughters': 2,\n",
       "          'day': 1,\n",
       "          'days': 1,\n",
       "          'death': 1,\n",
       "          'death.a': 1,\n",
       "          'declare': 1,\n",
       "          'delightful': 1,\n",
       "          'deny': 1,\n",
       "          'determined': 2,\n",
       "          'discovered': 1,\n",
       "          'done': 1,\n",
       "          'dont': 1,\n",
       "          'door': 1,\n",
       "          'doorof': 1,\n",
       "          'doors': 1,\n",
       "          'drank': 1,\n",
       "          'drawers': 1,\n",
       "          'drink': 2,\n",
       "          'drop': 1,\n",
       "          'eagerto': 1,\n",
       "          'eldest': 9,\n",
       "          'eldest.': 1,\n",
       "          'eldestleading': 1,\n",
       "          'empty': 1,\n",
       "          'enough.when': 1,\n",
       "          'entertained': 1,\n",
       "          'even': 1,\n",
       "          'evening': 3,\n",
       "          'every': 3,\n",
       "          'fast': 3,\n",
       "          'fear': 1,\n",
       "          'feel': 2,\n",
       "          'fell': 1,\n",
       "          'fellow': 1,\n",
       "          'fight': 1,\n",
       "          'find': 3,\n",
       "          'fine': 2,\n",
       "          'fineclothes': 1,\n",
       "          'flew': 1,\n",
       "          'floor': 1,\n",
       "          'follow': 1,\n",
       "          'followed': 1,\n",
       "          'foot': 1,\n",
       "          'forgotten': 1,\n",
       "          'found': 3,\n",
       "          'frightened': 1,\n",
       "          'fromwhich': 1,\n",
       "          'full': 1,\n",
       "          'gave': 1,\n",
       "          'get': 1,\n",
       "          'given': 3,\n",
       "          'glass': 1,\n",
       "          'glittered': 1,\n",
       "          'glitteringdiamonds': 1,\n",
       "          'go': 1,\n",
       "          'going': 4,\n",
       "          'golden': 3,\n",
       "          'goodcounsel': 1,\n",
       "          'gown': 2,\n",
       "          'great': 1,\n",
       "          'ground': 1,\n",
       "          'grove': 2,\n",
       "          'hand': 1,\n",
       "          'hands': 1,\n",
       "          'handsome': 1,\n",
       "          'happened': 6,\n",
       "          'happy': 1,\n",
       "          'hardly': 1,\n",
       "          'hardtask': 1,\n",
       "          'head': 1,\n",
       "          'heanswered': 1,\n",
       "          'hear': 1,\n",
       "          'heard': 3,\n",
       "          'hearing': 1,\n",
       "          'heat': 1,\n",
       "          'heavy': 1,\n",
       "          'hesnored': 1,\n",
       "          'himselfdown': 1,\n",
       "          'hiswife': 1,\n",
       "          'hold': 1,\n",
       "          'holes': 1,\n",
       "          'home': 1,\n",
       "          'horns': 1,\n",
       "          'however': 1,\n",
       "          'ifhe': 1,\n",
       "          'illuminated': 1,\n",
       "          'intothe': 1,\n",
       "          'intwelve': 1,\n",
       "          'invisible': 2,\n",
       "          'isnothing': 1,\n",
       "          'itall': 1,\n",
       "          'itis': 1,\n",
       "          'joy': 1,\n",
       "          'joy.so': 1,\n",
       "          'jumped': 1,\n",
       "          'king': 10,\n",
       "          'kingasked': 1,\n",
       "          'kingcalled': 1,\n",
       "          'kingreigned': 1,\n",
       "          'kings': 3,\n",
       "          'kingsheir': 1,\n",
       "          'know': 3,\n",
       "          'known': 1,\n",
       "          'laid': 2,\n",
       "          'lake': 4,\n",
       "          'land': 1,\n",
       "          'landed': 1,\n",
       "          'laughedheartily': 1,\n",
       "          'lay': 2,\n",
       "          'leave': 2,\n",
       "          'leaves': 3,\n",
       "          'leavesyou': 1,\n",
       "          'ledto': 1,\n",
       "          'left': 1,\n",
       "          'lie': 1,\n",
       "          'life': 1,\n",
       "          'like': 1,\n",
       "          'liked': 1,\n",
       "          'listening': 1,\n",
       "          'little': 3,\n",
       "          'lives': 1,\n",
       "          'locked': 1,\n",
       "          'longer': 1,\n",
       "          'looked': 1,\n",
       "          'lose': 2,\n",
       "          'lost': 1,\n",
       "          'loud': 3,\n",
       "          'luck': 2,\n",
       "          'made': 2,\n",
       "          'manner.now': 1,\n",
       "          'many': 1,\n",
       "          'married': 1,\n",
       "          'merry': 1,\n",
       "          'met': 1,\n",
       "          'middle': 1,\n",
       "          'might': 3,\n",
       "          'mightwe': 1,\n",
       "          'mischance': 1,\n",
       "          'moreof': 1,\n",
       "          'morning': 4,\n",
       "          'mouth': 1,\n",
       "          'music': 1,\n",
       "          'nail': 1,\n",
       "          'never': 1,\n",
       "          'next': 2,\n",
       "          'night': 5,\n",
       "          'night.when': 1,\n",
       "          'nights': 1,\n",
       "          'nobodycould': 1,\n",
       "          'noise': 3,\n",
       "          'nothing': 2,\n",
       "          'notsucceed': 1,\n",
       "          'obliged': 1,\n",
       "          'oclock': 1,\n",
       "          'off.the': 1,\n",
       "          'ofgold': 1,\n",
       "          'ofthe': 1,\n",
       "          'old': 4,\n",
       "          'one': 6,\n",
       "          'onyou': 1,\n",
       "          'open': 2,\n",
       "          'openedtheir': 1,\n",
       "          'order': 1,\n",
       "          'ordered': 1,\n",
       "          'orderedfine': 1,\n",
       "          'orwhat': 1,\n",
       "          'others': 2,\n",
       "          'outer': 1,\n",
       "          'pass': 1,\n",
       "          'passed': 1,\n",
       "          'person': 1,\n",
       "          'pieces': 1,\n",
       "          'place': 1,\n",
       "          'placed': 1,\n",
       "          'pretend': 1,\n",
       "          'prince': 1,\n",
       "          'princes': 5,\n",
       "          'princess': 3,\n",
       "          'princesses': 12,\n",
       "          'princesses.one': 1,\n",
       "          'princessesdanced': 1,\n",
       "          'princessesthere': 1,\n",
       "          'promisingto': 1,\n",
       "          'pulled': 1,\n",
       "          'put': 4,\n",
       "          'puton': 1,\n",
       "          'quite': 2,\n",
       "          'quiteworn': 1,\n",
       "          'ran': 1,\n",
       "          'ready': 1,\n",
       "          'received': 1,\n",
       "          'returned': 1,\n",
       "          'right': 2,\n",
       "          'robes': 1,\n",
       "          'room': 1,\n",
       "          'rose': 1,\n",
       "          'rowed': 1,\n",
       "          'rowing': 2,\n",
       "          'royal': 1,\n",
       "          'safe': 2,\n",
       "          'said': 13,\n",
       "          'saidhe': 1,\n",
       "          'saidwas': 1,\n",
       "          'sank': 1,\n",
       "          'saw': 1,\n",
       "          'second': 2,\n",
       "          'secret': 2,\n",
       "          'secretly': 1,\n",
       "          'see': 1,\n",
       "          'seemed': 1,\n",
       "          'set': 1,\n",
       "          'several': 1,\n",
       "          'shoes': 5,\n",
       "          'shore': 1,\n",
       "          'shouting': 1,\n",
       "          'showed': 1,\n",
       "          'side': 2,\n",
       "          'silly': 1,\n",
       "          'silver': 1,\n",
       "          'simpleton': 1,\n",
       "          'sister': 2,\n",
       "          'sisters': 2,\n",
       "          'sit': 1,\n",
       "          'skipped': 1,\n",
       "          'sleepingdraught': 1,\n",
       "          'slept': 2,\n",
       "          'slowly': 1,\n",
       "          'snore': 1,\n",
       "          'snoring': 1,\n",
       "          'soldier': 15,\n",
       "          'soldiersaid': 1,\n",
       "          'soldiersaw': 1,\n",
       "          'soles': 1,\n",
       "          'someonetook': 1,\n",
       "          'son': 2,\n",
       "          'sons': 1,\n",
       "          'soon': 5,\n",
       "          'soundly': 1,\n",
       "          'sparkled': 1,\n",
       "          'stairs': 2,\n",
       "          'stepped': 1,\n",
       "          'still': 1,\n",
       "          'stir': 1,\n",
       "          'stood': 2,\n",
       "          'strange': 1,\n",
       "          'sure': 2,\n",
       "          'take': 2,\n",
       "          'takenbefore': 1,\n",
       "          'taking': 1,\n",
       "          'task.he': 1,\n",
       "          'terribly': 1,\n",
       "          'thebottom': 1,\n",
       "          'theirtwelve': 1,\n",
       "          'thelake': 1,\n",
       "          'thenall': 1,\n",
       "          'theopposite': 1,\n",
       "          'theprince': 1,\n",
       "          'theprincess': 1,\n",
       "          'theprincesses': 2,\n",
       "          'therewas': 1,\n",
       "          'thesoldier': 2,\n",
       "          'thetwelve': 1,\n",
       "          'theyoungest': 1,\n",
       "          'theywere': 1,\n",
       "          'thing': 1,\n",
       "          'thinghappened': 1,\n",
       "          'think': 1,\n",
       "          'thinking': 1,\n",
       "          'third': 4,\n",
       "          'though': 1,\n",
       "          'thought': 1,\n",
       "          'three': 3,\n",
       "          'threebranches': 1,\n",
       "          'threw': 1,\n",
       "          'till': 2,\n",
       "          'time': 5,\n",
       "          'timei': 1,\n",
       "          'timetill': 1,\n",
       "          'tired': 2,\n",
       "          'today': 1,\n",
       "          'token': 1,\n",
       "          'told': 1,\n",
       "          'too.on': 1,\n",
       "          'took': 2,\n",
       "          'trap-door': 2,\n",
       "          'travelling': 1,\n",
       "          'tree': 1,\n",
       "          'trees': 2,\n",
       "          'tremble': 1,\n",
       "          'tried': 1,\n",
       "          'trod': 1,\n",
       "          'true': 1,\n",
       "          'trumpets': 1,\n",
       "          'try': 1,\n",
       "          'twelve': 8,\n",
       "          'undertake': 1,\n",
       "          'undressed': 1,\n",
       "          'uneasy': 1,\n",
       "          'us': 1,\n",
       "          'use': 1,\n",
       "          'usual': 1,\n",
       "          'vain': 1,\n",
       "          'verymuch': 1,\n",
       "          'verywell': 1,\n",
       "          'waiting': 1,\n",
       "          'wall': 1,\n",
       "          'warm': 1,\n",
       "          'wasof': 1,\n",
       "          'wastaken': 1,\n",
       "          'watch': 1,\n",
       "          'watched': 1,\n",
       "          'way': 2,\n",
       "          'weather': 1,\n",
       "          'well': 3,\n",
       "          'went': 11,\n",
       "          'werequite': 1,\n",
       "          'wereshut': 1,\n",
       "          'wherever': 1,\n",
       "          'whether': 1,\n",
       "          'whileyou': 1,\n",
       "          'whoever': 1,\n",
       "          'wife': 1,\n",
       "          'willbefall': 1,\n",
       "          'willing': 1,\n",
       "          'wine': 3,\n",
       "          'wiserthing': 1,\n",
       "          'wished': 1,\n",
       "          'without': 1,\n",
       "          'woman': 2,\n",
       "          'wood': 1,\n",
       "          'worn': 2,\n",
       "          'would': 2,\n",
       "          'wouldsay': 1,\n",
       "          'wounded': 1,\n",
       "          'yet': 1,\n",
       "          'youhear': 1,\n",
       "          'young': 1,\n",
       "          'youngest': 5,\n",
       "          'youngestprincess': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_wct = FreqDist(clean_tokens)\n",
    "fd_wct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soldier', 15),\n",
       " ('said', 13),\n",
       " ('princesses', 12),\n",
       " ('went', 11),\n",
       " ('king', 10),\n",
       " ('came', 10),\n",
       " ('eldest', 9),\n",
       " ('twelve', 8),\n",
       " ('one', 6),\n",
       " ('bed', 6)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_nw = FreqDist(clean_tokens)\n",
    "fd_nw.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
